import adrqn_agent
import run_experiment

# ADRQN Agent
AGENT_CLASS = @AdrqnAgent
AdrqnAgent.gamma = 0.995
AdrqnAgent.learning_rate = 0.005
AdrqnAgent.explore = 500
AdrqnAgent.replay_buffer_size=500000
AdrqnAgent.sample_length=20
AdrqnAgent.batch_size = 64
AdrqnAgent.eps_start = 0.9
AdrqnAgent.eps_end = 0.01
AdrqnAgent.eps_decay = 10
AdrqnAgent.tf_device = '/gpu:0'  # '/cpu:*' use for non-GPU version

# ADRQN class
ADRQN.hidden_size = 128
ADRQN.out_size = 128

# run_experiment.py
run_experiment.training_steps = 500 # originally 10000
run_experiment.num_iterations = 500 # originally 10005
run_experiment.checkpoint_every_n = 100 # originally 50
run_one_iteration.evaluate_every_n = 5 # originally 10
# run_one_iteration.num_evaluation_games = 2 # debug

# Small Hanabi.
create_environment.game_type = 'Hanabi-Small'
create_environment.num_players = 2

create_agent.agent_type = 'ADRQN'
create_obs_stacker.history_size = 1
